{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Human Detection in an aerial video.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9Y8ZmfXG3Tf",
        "outputId": "60be2aac-1ee0-4a59-e6de-68a7cf875f04"
      },
      "source": [
        "!git clone https://github.com/Himanshu0221/Human-Detection-in-an-aerial-video.git\n",
        "%cd Human-Detection-in-an-aerial-video"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Human-Detection-in-an-aerial-video'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n",
            "/content/Human-Detection-in-an-aerial-video/Human-Detection-in-an-aerial-video\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zflNQaJmHHEp"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "HumanDetection_cascade = cv2.CascadeClassifier(\"haarcascade_fullbody.xml\")\n",
        "\n",
        "# Function to perform human detection from Video. Pass an video as a variable.\n",
        "def HumanDetection(frame):\n",
        "\n",
        "    Humans = HumanDetection_cascade.detectMultiScale( frame, 1.1, 1)\n",
        "    # To draw a rectangle on each Humans\n",
        "    for (x,y,w,h) in Humans:\n",
        "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
        "        font = cv2.FONT_HERSHEY_DUPLEX\n",
        "        cv2.putText(frame, 'Person', (x + 6, y - 6), font, 0.5, (0, 255, 0), 1)\n",
        "        # Display frames in a window\n",
        "    return frame"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CI_5xvPH6si",
        "outputId": "65a33ce4-c486-44c0-a325-e2acf062e632"
      },
      "source": [
        "import cv2\n",
        "cap = cv2.VideoCapture('TopDown_AerialVideo_1080.mp4')\n",
        "ret, frame = cap.read()\n",
        "frame_height, frame_width, _ = frame.shape\n",
        "out = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
        "print(\"Processing Video...\")\n",
        "while cap.isOpened():\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    out.release()\n",
        "    break\n",
        "  output = HumanDetection(frame)\n",
        "  out.write(output)\n",
        "out.release()\n",
        "print(\"Done processing video\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing Video...\n",
            "Done processing video\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4O_BxNcIy2z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}